# RAGベースAIコーチングbot - MVP要件定義書

要件定義の作成原則
- **「あったらいいな」は絶対に作らない**
- **拡張可能性のための余分な要素は一切追加しない**
- **将来の「もしかして」のための準備は禁止**
- **今、ここで必要な最小限の要素のみ**

## 1. プロジェクト概要

### 1.1 成果目標
Difyプラットフォームを活用し、専門的なコーチング理論（システムRAG）と個別クライアントデータ（ユーザーRAG）を統合したAIコーチングbotを4週間で構築・運用開始する。

### 1.2 成功指標

#### 定量的指標
- 応答時間: 3-5秒以内
- 回答精度: 専門知識からの引用率80%以上
- システム稼働率: 95%以上
- クライアント満足度: 5段階評価で平均4以上
- 週次利用率: 登録クライアントの70%以上が週1回以上利用

#### 定性的指標
- クライアントが「理解されている」と感じる共感的な応答
- コーチング理論に基づいた専門的なアドバイス提供
- 個別のCOM:PASSデータを考慮したパーソナライズ応答
- コーチが会話履歴を確認し適切に介入できる体制
- MVP段階での学びを本格展開に活かせる知見獲得

## 2. システム全体像

### 2.1 主要機能一覧
- **システムRAG**: 専門知識（テキスト資料200個 + 動画文字起こし50時間分）のベクトル検索
- **ユーザーRAG**: 個別クライアントのCOM:PASSデータ（目標、タスク、日々のログ等）のベクトル検索
- **統合AIチャット**: 上記2つのRAGを統合したハイブリッド検索による応答生成
- **会話履歴管理**: クライアント別の会話記録自動保存・閲覧
- **週次データ更新**: COM:PASSからのデータエクスポート → Difyナレッジベース更新

### 2.2 ユーザーロールと権限

- **ゲスト**: アクセス不可（ログイン画面のみ表示）
- **クライアント（エンドユーザー）**: AIチャット利用、自分の会話履歴閲覧、プロフィール設定
- **コーチ（管理者）**: 全機能アクセス
  - システムRAG管理（専門知識の追加・編集）
  - ユーザーRAG管理（COM:PASSデータのアップロード）
  - 全クライアントの会話履歴閲覧
  - プロンプト調整
  - ワークフロー設定（危機検出等）
  - クライアント管理（追加・削除・トークン発行）

### 2.3 UI/UX要件

#### デバイス対応
- **クライアント向け機能（AIチャット）**: **スマホ対応必須**
  - 対象ページ: D-001（ログイン）、D-002（AIチャット）、D-003（会話履歴）
  - レスポンシブデザイン必須
  - タッチ操作最適化
  - モバイルブラウザ（iOS Safari、Android Chrome）での動作保証
  - PWA対応（オプション: ホーム画面追加可能）

- **コーチ向け機能（管理画面）**: **PC想定**
  - 対象ページ: D-004〜D-009（全管理機能）
  - デスクトップブラウザ（Chrome、Edge、Firefox）での動作保証
  - 大画面での作業効率重視
  - スマホ対応は不要（MVP段階）

#### Dify標準UIの対応状況
- **クライアント向けチャットUI**: スマホ対応済み（Dify標準）
  - レスポンシブデザイン完備
  - タッチ操作対応
  - モバイルブラウザ最適化済み
  - 追加カスタマイズ不要

- **管理画面UI**: PC向け（Dify標準）
  - デスクトップ最適化
  - マルチカラムレイアウト
  - 追加カスタマイズ不要

#### MVP段階のUI方針
- Dify標準UIをそのまま使用（カスタマイズなし）
- スマホ対応はDify標準機能で実現
- 本番化時にカスタムUIを検討（ブランディング等）

### 2.4 認証・認可要件

- **認証方式**: Dify標準認証（メール + パスワード）
  - 選定理由: 開発工数ゼロ、MVP段階で十分、後でSupabase Authに移行可能
- **セキュリティレベル**: 機密情報（メンタルヘルスデータに準ずる）
  - HTTPS必須（本番環境）
  - パスワードハッシュ化（Dify標準実装）
  - セッション管理（Dify標準実装）
  - 会話データのユーザー分離（Dify標準実装）
- **管理機能**: 必須
  - ユーザー管理、ナレッジベース管理、会話履歴管理、プロンプト編集（全てDify標準提供）

## 3. ページ詳細仕様

### 3.1 D-001: ログイン

#### 目的
システムへの認証済みアクセスを提供

#### 主要機能
- メールアドレス + パスワード入力
- ログイン処理
- エラーハンドリング

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 認証 | ログイン | メール、パスワード | セッショントークン、ユーザー情報 |

#### 処理フロー
1. ユーザーがメール・パスワードを入力
2. Dify認証システムが検証
3. 成功時: チャット画面へリダイレクト / 失敗時: エラーメッセージ表示

#### データ構造（概念）
```yaml
User:
  識別子: user_id (UUID)
  基本情報:
    - email（必須）
    - password_hash（必須）
    - role（必須: client/coach）
  メタ情報:
    - created_at
    - last_login_at
```

---

### 3.2 D-002: AIチャット（メインページ）

#### 目的
クライアントがシステムRAG + ユーザーRAGを活用したAIコーチと対話

#### 主要機能
- テキストメッセージ送信
- AIからの共感的・専門的応答受信
- システムRAG（コーチング理論体系）からの引用表示
- ユーザーRAG（個別COM:PASSデータ）を考慮したパーソナライズ応答
- 会話履歴の自動保存
- 新しい会話の開始

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | 会話履歴取得 | session_id | 過去のメッセージ一覧 |
| 作成 | メッセージ送信 | テキスト内容 | AI応答（3-5秒以内） |
| 作成 | 新しい会話開始 | なし | 新しいsession_id |

#### 処理フロー
1. ユーザーがメッセージを入力・送信
2. Difyワークフローが起動
   - システムRAG検索（専門知識から関連情報を抽出）
   - ユーザーRAG検索（個別データから関連情報を抽出）
   - 統合プロンプト生成
3. Claude 3.5 Haiku/Sonnetが応答生成
4. 引用元情報と共に応答を表示
5. 会話履歴に自動保存

#### データ構造（概念）
```yaml
Conversation:
  識別子: session_id (UUID)
  基本情報:
    - user_id（必須）
    - created_at（必須）
  関連:
    - Message（1対多）

Message:
  識別子: message_id (UUID)
  基本情報:
    - session_id（必須）
    - role（必須: user/assistant）
    - content（必須）
    - citations（任意: 引用元情報）
  メタ情報:
    - created_at
    - tokens_used
```

---

### 3.3 D-003: 会話履歴（クライアント用）

#### 目的
クライアント自身の過去の会話を確認

#### 主要機能
- 過去のセッション一覧表示
- 特定セッションの詳細閲覧
- セッションの削除

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | セッション一覧 | user_id | セッション一覧（日時順） |
| 取得 | セッション詳細 | session_id | メッセージ一覧 |
| 削除 | セッション削除 | session_id | 削除完了通知 |

---

### 3.4 D-004: 管理ダッシュボード（コーチ専用）

#### 目的
システム全体の統括管理

#### 主要機能
- システム稼働状況の確認
- クライアント数・会話数の概要表示
- 各管理機能へのナビゲーション

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | システム統計 | なし | 会話数、ユーザー数、API使用量等 |

---

### 3.5 D-005: ナレッジベース管理（コーチ専用）

#### 目的
システムRAG（専門知識）とユーザーRAG（個別データ）の構築・更新

#### 主要機能
- ファイルアップロード（PDF、DOCX、TXT）
- チャンク設定調整（チャンクサイズ、オーバーラップ）
- ベクトル化進捗確認
- 検索精度テスト
- ファイル削除・更新

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 作成 | ファイルアップロード | ファイル、ナレッジベース指定 | アップロード完了、ベクトル化開始 |
| 取得 | ベクトル化状況確認 | dataset_id | 進捗率、処理済みチャンク数 |
| 更新 | チャンク設定変更 | チャンクサイズ、オーバーラップ | 設定更新完了 |
| 削除 | ファイル削除 | document_id | 削除完了 |

#### データ構造（概念）
```yaml
KnowledgeBase:
  識別子: dataset_id (UUID)
  基本情報:
    - name（必須: "システムRAG" / "ユーザーRAG_{user_id}"）
    - type（必須: system/user）
    - embedding_model（必須: text-embedding-3-small）
  設定:
    - chunk_size（デフォルト: 500トークン）
    - overlap（デフォルト: 50トークン）
  メタ情報:
    - created_at
    - updated_at
    - total_documents
    - total_chunks
  関連:
    - Document（1対多）

Document:
  識別子: document_id (UUID)
  基本情報:
    - dataset_id（必須）
    - filename（必須）
    - file_type（必須）
    - content（必須）
  メタ情報:
    - uploaded_at
    - vectorized_at
    - chunk_count
  関連:
    - Chunk（1対多）

Chunk:
  識別子: chunk_id (UUID)
  基本情報:
    - document_id（必須）
    - content（必須）
    - embedding（必須: vector[1536]）
    - position（必須: チャンク順序）
  メタ情報:
    - created_at
```

---

### 3.6 D-006: 会話履歴管理（コーチ専用）

#### 目的
全クライアントの会話を確認し、必要に応じて介入準備

#### 主要機能
- 全クライアントのセッション一覧表示
- クライアント別フィルタリング
- 特定セッションの詳細閲覧
- 危機フラグの確認

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | 全セッション一覧 | なし | 全クライアントのセッション一覧 |
| 取得 | クライアント別セッション | user_id | 特定クライアントのセッション一覧 |
| 取得 | セッション詳細 | session_id | メッセージ一覧、引用元情報 |

---

### 3.7 D-007: プロンプト編集（コーチ専用）

#### 目的
AIの応答スタイル・ペルソナ・指示の調整

#### 主要機能
- システムプロンプト編集
- A/Bテスト設定
- バージョン管理
- プレビュー機能

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | 現在のプロンプト取得 | app_id | プロンプトテキスト |
| 更新 | プロンプト更新 | 新しいプロンプトテキスト | 更新完了 |
| 作成 | テストプロンプト実行 | テストメッセージ | AI応答（テスト用） |

---

### 3.8 D-008: ワークフロー編集（コーチ専用）

#### 目的
RAG検索フロー、危機検出フロー等の調整

#### 主要機能
- ワークフロー図の視覚的編集
- ノード（RAG検索、条件分岐、LLM呼び出し等）の追加・削除
- 危機キーワード検出設定
- ワークフロー実行テスト

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | ワークフロー取得 | workflow_id | ワークフローJSON |
| 更新 | ワークフロー更新 | 更新されたワークフローJSON | 更新完了 |
| 作成 | ワークフローテスト | テスト入力 | 実行結果、各ノードの出力 |

---

### 3.9 D-009: ユーザー管理（コーチ専用）

#### 目的
クライアントの追加・削除・アクセストークン管理

#### 主要機能
- クライアント追加（メール招待）
- アクセストークン発行
- クライアント情報編集
- クライアント削除

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | クライアント一覧 | なし | 全クライアントの情報 |
| 作成 | クライアント追加 | メールアドレス | 招待メール送信、トークン発行 |
| 更新 | クライアント情報編集 | user_id、更新内容 | 更新完了 |
| 削除 | クライアント削除 | user_id | 削除完了 |

---

### 3.10 C-001: データエクスポート（COM:PASS側開発）

#### 目的
COM:PASSデータをDifyユーザーRAGに取り込むための前処理

#### 主要機能
- ユーザー選択
- エクスポート対象期間指定（デフォルト: 直近30日）
- Markdown形式テキストファイル生成
- ダウンロード

#### 必要な操作
| 操作種別 | 操作内容 | 必要な入力 | 期待される出力 |
|---------|---------|-----------|---------------|
| 取得 | ユーザーデータエクスポート | user_id、期間 | テキストファイル（.txt） |

#### 処理フロー
1. コーチがCOM:PASS管理画面にログイン
2. クライアント選択、期間指定（任意）
3. 「エクスポート」ボタンクリック
4. バックエンドがデータ取得・Markdown形式整形
5. テキストファイルダウンロード
6. コーチがDify D-005でアップロード
7. 自動的にベクトル化・検索可能に

#### データ構造（概念）
```yaml
ExportedData:
  基本情報:
    - client_name（必須）
    - export_date（必須）
  コンテンツ:
    - goals（目標一覧）
    - tasks（タスク実行状況、直近50件）
    - logs（日々のログ、直近30日）
    - reflections（振り返り記録）
    - action_plans（改善計画）
```

#### エクスポートファイル形式例
```markdown
# クライアント: {ユーザー名}
エクスポート日時: {YYYY-MM-DD HH:mm}

## 目標
- {Goal 1}
- {Goal 2}

## 最近のタスク実行状況
- {Task 1} (完了日: {date})
- {Task 2} (進行中)

## 日々のログ（直近30日）
### {YYYY-MM-DD}
感情: {emotion}
状態: {state}
内容: {content}

### {YYYY-MM-DD}
...

## 振り返り記録
{Reflection content}

## 改善計画
{ActionPlan content}
```

## 4. データ設計概要

### 4.1 主要エンティティ

```yaml
User:
  概要: システム利用者（クライアント/コーチ）
  主要属性:
    - 認証情報: email, password_hash, role
    - プロフィール: name, created_at, last_login_at
  関連:
    - Conversation（1対多）
    - KnowledgeBase（1対1: ユーザーRAG専用）

Conversation:
  概要: 1つのチャットセッション
  主要属性:
    - 識別: session_id, user_id
    - メタ: created_at
  関連:
    - User（多対1）
    - Message（1対多）

Message:
  概要: 会話内の1メッセージ
  主要属性:
    - 内容: role, content, citations
    - メタ: created_at, tokens_used
  関連:
    - Conversation（多対1）

KnowledgeBase:
  概要: RAGのナレッジベース（システム/ユーザー別）
  主要属性:
    - 設定: name, type, embedding_model, chunk_size, overlap
    - メタ: created_at, total_documents, total_chunks
  関連:
    - Document（1対多）

Document:
  概要: ナレッジベース内の1ファイル
  主要属性:
    - 識別: filename, file_type
    - 内容: content
    - メタ: uploaded_at, vectorized_at, chunk_count
  関連:
    - KnowledgeBase（多対1）
    - Chunk（1対多）

Chunk:
  概要: ドキュメントの分割チャンク（ベクトル化単位）
  主要属性:
    - 内容: content, embedding (vector[1536]), position
  関連:
    - Document（多対1）
```

### 4.2 エンティティ関係図
```
User ─┬─ Conversation  （1対多）
      └─ KnowledgeBase （1対1: ユーザーRAG）

Conversation ─── Message  （1対多）

KnowledgeBase ─── Document  （1対多）

Document ─── Chunk  （1対多）
```

### 4.3 バリデーションルール
```yaml
email:
  - ルール: 有効なメール形式、一意
  - 理由: アカウント識別とログイン用

password:
  - ルール: 8文字以上
  - 理由: セキュリティ確保（MVP段階は簡易）

role:
  - ルール: "client" または "coach" のみ
  - 理由: 権限管理の基礎

chunk_size:
  - ルール: 100-2000トークン
  - 理由: 検索精度とコストのバランス

embedding:
  - ルール: vector[1536]型
  - 理由: OpenAI text-embedding-3-small仕様
```

## 5. 制約事項

### 外部API制限
- **Claude API (Free Tier)**: 5 RPM、20,000 TPM
  - 制約: 複数クライアント同時利用時にレート制限の可能性
  - 対策: Build Tier 1（$5デポジット）で拡大
- **OpenAI API (Tier 1)**: 500 RPM、200,000 TPD
  - 制約: 大量の文字起こし処理時に日次上限の可能性
  - 対策: 並列処理の分散実行

### 技術的制約
- **Supabase無料枠**: 500MB、60同時接続
  - 制約: ベクトルデータ約33万件まで（MVP段階では十分）
- **DigitalOcean Droplet 4GB**: 5-15同時ユーザー想定
  - 制約: それ以上の同時接続時はスペックアップ必要
- **Dify標準認証**: COM:PASSとのSSO未対応（MVP段階）
  - 制約: ユーザーは2つのシステムに別々にログイン
  - 対策: MVP後にSupabase Auth統合

## 6. 複合API処理（バックエンド内部処理）

### 複合処理-001: ハイブリッドRAG検索 + LLM応答生成

**トリガー**: クライアントがチャットでメッセージ送信

**フロントエンドAPI**: POST /v1/chat-messages

**バックエンド内部処理**:
1. **ユーザー認証確認** - セッショントークン検証
2. **システムRAG検索** - 専門知識ベクトルDBから類似チャンク取得（Top 5）
3. **ユーザーRAG検索** - 個別データベクトルDBから類似チャンク取得（Top 3）
4. **統合プロンプト生成** - システムRAG結果 + ユーザーRAG結果 + ユーザーメッセージを統合
5. **LLM呼び出し（Claude API）** - プロンプトキャッシング利用
6. **応答整形** - 引用元情報の付与
7. **会話履歴保存** - PostgreSQLに永続化
8. **レスポンス返却** - フロントエンドへ

**結果**: AI応答テキスト + 引用元情報

**外部サービス依存**: Supabase PostgreSQL + pgvector、Claude API

**想定処理時間**: 3-5秒

---

### 複合処理-002: ドキュメントベクトル化

**トリガー**: コーチがナレッジベース管理でファイルアップロード

**フロントエンドAPI**: POST /datasets/{dataset_id}/documents

**バックエンド内部処理**:
1. **ファイル検証** - ファイル形式、サイズチェック
2. **テキスト抽出** - PDF/DOCX/TXTからプレーンテキスト抽出
3. **チャンク分割** - 設定に基づき分割（デフォルト: 500トークン、オーバーラップ50）
4. **Embeddings生成（OpenAI API）** - 各チャンクをベクトル化（並列処理）
5. **pgvectorに保存** - ベクトルと元テキストを紐付けて保存
6. **進捗更新** - フロントエンドに進捗通知

**結果**: ベクトル化完了通知

**外部サービス依存**: OpenAI API、Supabase pgvector

**想定処理時間**: 10-60秒（ファイルサイズによる）

---

### 複合処理-003: 週次ユーザーRAG更新

**トリガー**: コーチがCOM:PASSでデータエクスポート → Difyでアップロード

**フロントエンドAPI（COM:PASS側）**: GET /api/admin/export/{user_id}
**フロントエンドAPI（Dify側）**: POST /datasets/{user_rag_dataset_id}/documents

**バックエンド内部処理**:
1. **COM:PASSデータ取得** - FastAPI経由で目標、タスク、ログ、振り返り等を取得
2. **Markdown形式整形** - エクスポート用テキスト生成
3. **ファイルダウンロード** - コーチがローカルに保存
4. **Difyアップロード** - コーチが手動でアップロード
5. **既存データ削除** - 古いユーザーRAGドキュメントを削除
6. **新規ベクトル化** - 複合処理-002と同様の処理
7. **完了通知** - 次回チャットから最新データ反映

**結果**: ユーザーRAG更新完了

**外部サービス依存**: COM:PASS FastAPI、OpenAI API、Supabase pgvector

**想定頻度**: 週1回

## 7. 技術スタック

### フロントエンド（Dify標準）
- **フレームワーク**: Next.js 14、React 18、TypeScript
- **UIライブラリ**: Tailwind CSS、Headless UI
- **状態管理**: React Context API
- **開発工数**: 0時間（Dify標準UIをそのまま使用）

### バックエンド
- **Dify API**: Flask、LangChain、Celery（非同期処理）
- **COM:PASS**: FastAPI、SQLAlchemy
- **開発工数**: 4-6時間（データエクスポートAPI追加のみ）

### データベース
- **Supabase PostgreSQL 16**: COM:PASSデータ + Difyメタデータ
- **pgvector拡張**: ベクトルストレージ（システムRAG + ユーザーRAG）
- **Redis**: セッション管理、キャッシュ（Dify標準）

### AI/ML
- **LLM**: Claude 3.5 Haiku（本番）、Claude 3.5 Sonnet（開発）
- **Embeddings**: OpenAI text-embedding-3-small
- **文字起こし**: OpenAI Whisper API

### インフラ
- **開発環境**: ローカル（Docker Compose）
- **テスト運用**: DigitalOcean Droplet 4GB RAM ($24/月)
- **本番環境**: DigitalOcean Droplet 8GB RAM ($48/月) ※スケール時

### 開発ツール
- **バージョン管理**: Git、GitHub
- **CI/CD**: 手動デプロイ（MVP）、GitHub Actions（本番化時）
- **モニタリング**: Dify標準ログ、Langfuse（オプション）

## 8. 必要な外部サービス・アカウント

### 必須サービス

| サービス名 | 用途 | 取得先 | 料金 | 備考 |
|-----------|------|--------|------|------|
| Anthropic Claude API | LLM（応答生成） | https://console.anthropic.com | Haiku: 入力$0.80/1M、出力$4.00/1M<br>Sonnet: 入力$3.00/1M、出力$15.00/1M | 新規アカウント$10クレジット<br>$5デポジット必要 |
| OpenAI API | Embeddings、Whisper | https://platform.openai.com | Embeddings: $0.02/1M<br>Whisper: $0.006/分 | 新規アカウント$5クレジット<br>$20-30チャージ推奨 |
| Supabase | PostgreSQL + pgvector | https://supabase.com | 無料枠: 500MB<br>Pro: $25/月 | 既存COM:PASSプロジェクト使用<br>pgvector有効化のみ |
| DigitalOcean | Difyホスティング | https://www.digitalocean.com | Droplet 4GB: $24/月 | 新規$200クレジット（60日）<br>ローカル開発時は不要 |

### オプションサービス

| サービス名 | 用途 | 取得先 | 料金 | 備考 |
|-----------|------|--------|------|------|
| Langfuse | LLM呼び出しトレース、コスト監視 | https://langfuse.com | 無料枠: 50,000 observations/月 | MVP後に検討 |

### 初期費用・月額費用

**初期費用（一度きり）**
- Claude APIデポジット: $5
- OpenAI APIチャージ: $20-30
- 動画文字起こし（50時間）: $18
- Embeddings（810万文字）: $0.25
- **合計: $43.25-$53.25**

**月額費用（テストユーザー10名想定）**
- DigitalOcean Droplet: $24（テスト運用時）
- Supabase: $0（無料枠）
- Claude API（1,000メッセージ/月）: $13.50
- OpenAI Embeddings（追加データ）: $1-2
- **合計: $38.50-$39.50/月**

**開発段階（ローカル）**: $14.50-$15.50/月（インフラ不要）

## 9. MVP開発スケジュール（4週間）

### Week 1: 環境構築 + システムRAG構築
- Day 1-2: 外部サービスアカウント取得、Difyローカルセットアップ
- Day 3-4: Supabase pgvector設定、専門知識ファイル整理
- Day 5-7: システムRAGアップロード・ベクトル化（200ファイル + 50時間文字起こし）

### Week 2: COM:PASS統合 + 初期テスト
- Day 8-9: データエクスポートAPI実装（C-001）
- Day 10-11: 初回データエクスポート → DifyユーザーRAGアップロード（5-10名分）
- Day 12-14: 基本プロンプト作成、ハイブリッド検索ワークフロー設定

### Week 3: チューニング + テスト運用開始
- Day 15-16: プロンプト調整、応答品質確認
- Day 17-18: テストクライアント招待、フィードバック収集
- Day 19-21: 問題修正、ワークフロー改善

### Week 4: 本番移行準備
- Day 22-23: DigitalOcean Dropletセットアップ、本番デプロイ
- Day 24-25: 本番環境テスト、パフォーマンス確認
- Day 26-28: ドキュメント整備、コーチ向けトレーニング、正式運用開始

## 10. 制約事項・リスク

### 制約事項
- MVP段階では1コーチのみ（複数コーチ管理は本番化時に実装）
- COM:PASS認証とDify認証は別々（SSO統合は本番化時に実装）
- 週次手動データ更新（自動化は本番化時に実装）
- 管理ダッシュボードはDify標準のみ（カスタム分析は本番化時に実装）

### リスク
- **クライアント数急増**: Droplet 4GBは5-15同時ユーザー想定、超過時はスペックアップ必要
- **APIコスト超過**: 想定以上の利用でClaude API料金増加、プロンプトキャッシング活用で軽減
- **RAG検索精度不足**: チャンク設定調整、プロンプト改善、リランク導入で対応
- **COM:PASSデータ形式変更**: エクスポートAPI修正必要（影響範囲小）

## 11. 今後の拡張予定（MVP後）

- 複数コーチ管理機能
- COM:PASS ⇔ Dify SSO統合
- 週次データ自動更新（バッチ処理）
- カスタム分析ダッシュボード
- モバイルアプリ対応
- 多言語対応
- エンタープライズ向けセキュリティ強化（2FA、HIPAA準拠等）

---

**作成日**: 2025-11-02
**バージョン**: MVP v1.0
**作成者**: BlueLamp レコンX + Claude Code
